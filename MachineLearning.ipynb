{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded, there are 321 features and 328135 samples, the shapes of the unindexed data is:\n",
      "y: (328135, 1), x: (328135, 321)\n",
      "\n",
      "For a threshold of 0.7, there are 144 good features, and 177 bad features\n",
      "There remains in the data 289870 samples with at most 5 missing values\n",
      "The number of invalid entries remaing in the dataset is 272938\n",
      "That is 0.006538802834987332 parts of the whole dataset\n",
      "Removed 21050 samples with outliers more than 10 standard deviations from the mean. There remains 268820 samples in the dataset.\n",
      "Standardized data by subtracting the mean and dividing by the standard deviation\n",
      "\n",
      "Created a balanced subset of the data, with 46448 samples, 23224 each of positive and negative samples\n",
      "\n",
      "Added dummy variable and replaced invalid entries with zeros\n",
      "The resultant dataarray tx has shapes (46448, 145)\n"
     ]
    }
   ],
   "source": [
    "# Importing numpy and functions\n",
    "import numpy as np\n",
    "import helpers as h\n",
    "from implementations import *\n",
    "\n",
    "# Loading the data\n",
    "X, xHeader, Y, yHeader, indexedX, indexedXheader, indexedY, indexedYheader = loadTrainingData()\n",
    "print('')\n",
    "# Cleaning/feature engineering the data\n",
    "yClean, xClean, xHeaderClean, removedFeatures = dataCleaning(Y,X,xHeader)\n",
    "print('')\n",
    "# Making a balanced data set to force the model to not just predict negatively all the time\n",
    "yBalanced, xBalanced, balancePrior = balanceData(yClean,xClean)\n",
    "print('')\n",
    "# Adding dummy variables and replacing the remaining invalid values by the mean\n",
    "tx = makeTrainingData(xBalanced)\n",
    "print(f'The resultant dataarray tx has shape {tx.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1 yielded a loss improvement from 0.5012917115177611 to 0.1552742181694449\n",
      "Run 2 yielded a loss improvement from 0.5071044133476856 to 0.15513740607157933\n",
      "Run 3 yielded a loss improvement from 0.5058127018299247 to 0.15725589352782068\n",
      "Run 4 yielded a loss improvement from 0.49542469587684357 to 0.15300931120396857\n",
      "Run 5 yielded a loss improvement from 0.4903649477877059 to 0.15504066222900187\n",
      "-----------------------------------------------------------------------------------------\n",
      "Averaging the parameters, the loss improves from 0.5 to 0.1565452697989322\n",
      "\n",
      "Run 1 yielded a loss improvement from 0.6931471805599084 to 0.47357670299947235\n",
      "Run 2 yielded a loss improvement from 0.6931471805599084 to 0.47152853137194933\n",
      "Run 3 yielded a loss improvement from 0.6931471805599084 to 0.4760067175154304\n",
      "Run 4 yielded a loss improvement from 0.6931471805599083 to 0.4749024434713034\n",
      "Run 5 yielded a loss improvement from 0.6931471805599083 to 0.4825389674534961\n",
      "-----------------------------------------------------------------------------------------\n",
      "Averaging the parameters, the loss improves from 0.6931471805600634 to 0.4791106044418823\n"
     ]
    }
   ],
   "source": [
    "# Initializing the parameters at zero and setting some constants\n",
    "initial_w = np.zeros(tx.shape[1])\n",
    "K = 5\n",
    "gamma = 0.01\n",
    "max_iter = 1000\n",
    "\n",
    "# Training a model with gradient descent with momentum\n",
    "w_gd_m, loss_gd_m = k_fold_cross_validation(yBalanced,tx,K,initial_w,max_iter,gamma, mse_gd_momentum, compute_loss)\n",
    "print('')\n",
    "# Training a model with logistic\n",
    "w_logistic, loss_logistic = k_fold_cross_validation(yBalanced,tx,K,initial_w,max_iter,gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109379, 322)\n"
     ]
    }
   ],
   "source": [
    "# Loading the test data\n",
    "xTest, xIndexedHeader = loadData('./Data/x_test.csv')\n",
    "print(xTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added dummy variable and replaced invalid entries with zeros\n",
      "Added dummy variable and replaced invalid entries with zeros\n",
      "0.0 32500.0\n"
     ]
    }
   ],
   "source": [
    "# Making predictions\n",
    "pred_gd = makePredictions(w_logistic,xTest[:,1:],xHeader,xHeaderClean,balancePrior)\n",
    "pred_logistic = makePredictions(w_logistic,xTest[:,1:],xHeader,xHeaderClean)\n",
    "# Counting predicted positive cases\n",
    "print(np.sum(pred_gd),np.sum(pred_logistic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_logistic[pred_logistic == 0] = -1\n",
    "h.create_csv_submission(xTest[:,0],pred_logistic,'./Predictions/balancedDataNoPrior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "StdVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
