{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing numpy and functions\n",
    "import numpy as np\n",
    "import helpers as h\n",
    "from implementations import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a random seed\n",
    "seed = 934586\n",
    "np.random.seed(seed)\n",
    "\n",
    "#### Setting some hyperparameters ########\n",
    "K = 5\n",
    "gamma = 0.01\n",
    "max_iter = 200\n",
    "featureThreshold = 0.7\n",
    "acceptableMissingValues = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded, there are 321 features and 328135 samples, the shapes of the unindexed data is:\n",
      "y: (328135, 1), x: (328135, 321)\n",
      "\n",
      "For a threshold of 0.7, there are 144 good features, and 177 bad features\n",
      "There remains in the data 289870 samples with at most 5 missing values\n",
      "The number of invalid entries remaing in the dataset is 272938\n",
      "That is 0.006538802834987332 parts of the whole dataset\n",
      "Removed 21050 samples with outliers more than 10 standard deviations from the mean. There remains 268820 samples in the dataset.\n",
      "Standardized data by subtracting the mean and dividing by the standard deviation\n",
      "\n",
      "Created a balanced subset of the data, with 46448 samples, 23224 each of positive and negative samples\n",
      "\n",
      "Added dummy variable and replaced invalid entries with zeros\n",
      "The resultant dataarray tx has shape (46448, 145)\n"
     ]
    }
   ],
   "source": [
    "# Loading the data\n",
    "X, xHeader, Y, yHeader, indexedX, indexedXheader, indexedY, indexedYheader = loadTrainingData()\n",
    "print('')\n",
    "# Cleaning/feature engineering the data\n",
    "yClean, xClean, xHeaderClean, removedFeatures = dataCleaning(Y,X,xHeader,featureThreshold,acceptableMissingValues)\n",
    "print('')\n",
    "# Making a balanced data set to force the model to not just predict negatively all the time\n",
    "yBalanced, xBalanced, balancePrior = balanceData(yClean,xClean)\n",
    "print('')\n",
    "# Adding dummy variables and replacing the remaining invalid values by the mean\n",
    "tx = makeTrainingData(xBalanced)\n",
    "print(f'The resultant dataarray tx has shape {tx.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the weights at zero\n",
    "initial_w = np.zeros(tx.shape[1])\n",
    "\n",
    "# Setting some lambdas to check for the best among them\n",
    "lambdas = np.logspace(-1,-0.5,10)\n",
    "# Looking for the best of the chosen lambdas\n",
    "train_loss, test_loss, bestLambda, best_w = determineLambda(yBalanced,tx,initial_w,lambdas,max_iter,K,gamma)\n",
    "\n",
    "# Plotting the training and testing errors as functions of lambda\n",
    "plt.plot(lambdas,train_loss,label='Training Loss', color='g')\n",
    "plt.plot(lambdas,test_loss,label='Testing Loss', color='r')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a model with logistic regression, with the chosen lambda\n",
    "#reg_logistic_regression_fixed_lambda = lambda y, tx, initial_w, max_iters, gamma: reg_logistic_regression(y,tx,bestLambda,initial_w,max_iters,gamma)\n",
    "#w_logistic, train_loss_logistic, test_loss_logistic = k_fold_cross_validation(yBalanced,tx,K,initial_w,max_iter,gamma,regressionFunction=reg_logistic_regression_fixed_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Making predictions ###############\n",
    "# Loading the test data\n",
    "xTest, xIndexedHeader = loadData('./Data/x_test.csv')\n",
    "print(xTest.shape)\n",
    "\n",
    "# Making predictions\n",
    "pred_logistic = makePredictions(best_w,xTest[:,1:],xHeader,xHeaderClean)\n",
    "# Counting predicted positive cases\n",
    "print(f'The model predicts {np.sum(pred_logistic)} positive cases')\n",
    "\n",
    "# Converting the predictions from 0/1 to -1/1, and making a prediction file ready for submission\n",
    "pred_logistic[pred_logistic == 0] = -1\n",
    "h.create_csv_submission(xTest[:,0], pred_logistic, f'./Predictions/regularizedLogistic_seed_{seed}_gamma_{gamma}_iter_{max_iter}_K_{K}_featShold_{featureThreshold}_missVals_{acceptableMissingValues}.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "StdVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
